# Real_time-Retail-Orders-ETL-pipeline
Real-Time Retail Orders ETL Pipeline with DatabricksÂ &amp;Â DeltaÂ Lake
This repository showcases a real-time data engineering pipeline that ingests streaming retail order data from JSON files using Apache Spark Structured Streaming in Databricks. The data undergoes transformation, including schema enforcement, null filtering, and timezone-based timestamp generation before being stored in a Delta Lake table.

Features:
	â€¢	ðŸ’¾ Real-time ingestion from file-based sources
	â€¢	ðŸ”„ Stream-based transformations using PySpark
	â€¢	ðŸ•’ Timezone-aware processed_time for audit tracking
	â€¢	âœ… Output stored in fault-tolerant Delta format
	â€¢	ðŸ”§ Manual patching for malformed or missing data
	â€¢	ðŸ“„ Complete project documentation & setup guide included

ðŸ“‚ Includes:
	â€¢	Full project notebook
	â€¢	Sample input files
	â€¢	Complete PDF documentation
	â€¢	README for setup and usage

ðŸ”— Technologies: Databricks, PySpark, Delta Lake, StructuredÂ Streaming,Â JSON

<img width="1366" height="768" alt="image" src="https://github.com/user-attachments/assets/7c92e0ad-b25e-43ff-8709-124bc6ec7895" />
<img width="1366" height="768" alt="image" src="https://github.com/user-attachments/assets/f67738c0-7256-4fca-954f-65ec4f4d65c5" />
<img width="1365" height="767" alt="image" src="https://github.com/user-attachments/assets/aa5b793e-cb8d-4bc0-baa9-215255861f30" />
<img width="1365" height="767" alt="image" src="https://github.com/user-attachments/assets/a12c1786-8bf1-4605-a664-fc62e044059c" />

